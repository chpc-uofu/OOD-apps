---
title: "Jupyter Lab"
attributes:
  cluster: 
    widget: "select"
    options:
      - "notchpeak"
      - "kingspeak"
      - "lonepeak"
      - "ash"
      - "tangent"
      - "frisco1"
      - "frisco2"
      - "frisco3"
      - "frisco4"
      - "frisco5"
      - "frisco6"
      - "frisco7"
      - "frisco8"
    help: |
      Select the cluster or Frisco node to create this session on.
  # Set the corresponding modules that need to be loaded for Jupyter to run
  #
  # @note It is called within the batch job as `module load <modules>` if
  #   defined
  # @example Do not load any modules
  #     modules: ""
  # @example Using default python module
  #     modules: "python"
  # @example Using specific python module
  #     modules: "python/3.5"
  # @example Using combination of modules
  #     modules: "python/3.5 cuda/8.0.44"
  #modules: "python/3.5.2 R/3.4.2"
  custom_environment:
    widget: text_area
    label: Environment Setup (drag text area to enlarge)
    help: "Enter commands (module load, source activate, etc) to create your desired JupyterLab environment; jupyter MUST be on your path. For instructions how to install ypur own Python using Miniconda see https://www.chpc.utah.edu/documentation/software/python-anaconda.php. If you don't have one yet use 'module load python/3.6.3 R/3.6.1'"
    value: |
        module load python/3.6.3 R/3.6.1

  num_cores:
    widget: "number_field"
    label: "Number of cores"
    value: 1
    help: "Maximum number of CPU cores on notchpeak-shared-short is 32, see [cluster help pages](https://www.chpc.utah.edu/resources/HPC_Clusters.php) for other cluster's node counts."
    min: 1
    step: 1
  bc_num_hours:
    value: 1
    min: 1
    step: 1
    help: "Maximum wall time on notchpeak-shared-short is 8 hours, general nodes 72 hours, owner nodes 14 days."
  bc_account:
    label: "Account"
    value: "notchpeak-shared-short"
  bc_queue:
    label: "Partition"
    value: "notchpeak-shared-short"
  memtask:
    widget: "text_field"
    value: "default"
    label: "Memory per job"
    help: |
      - **default** - Use default, 4 GB per task.
      - **512M** - Use 512 MB.
      - **128G** - Use 128 GB, this is the maximum on notchpeak-shared-short.
  gpu_type:
    label: "GPU type:count"
    help: |
      - GPU type:
          - **none** - No GPU
          - **k80** - Tesla K80 GPU(s) (double precision)
          - **1080ti** - GeForce 1080 Ti GPU(s) (single precision)
          - **2080ti** - GeForce 2080 Ti GPU(s) (single precision)
          - **titanv** - GeForce Titan V GPU(s) (single precision)
          - **c40** - Tesla C40 GPU (single precision)
          - **v100** - Tesla V100 GPU(s) (double precision)
      - GPU count: 
          - Specify count with :count after the GPU name (e.g. **v100:2**)
    value: "none"

form:
  - cluster
  - custom_environment
  - num_cores
  - bc_num_hours
  - memtask
  - bc_account
  - bc_queue
  - gpu_type
  - bc_email_on_started
